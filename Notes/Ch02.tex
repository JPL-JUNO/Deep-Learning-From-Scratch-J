\chapter{感知机}
本章将介绍感知机（perceptron）这一算法。感知机作为神经网络（深度学习）的起源的算法。因此，
学习感知机的构造是学习通向神经网络和深度学习的一种重要思想。
\section{感知机是什么}
感知机接收多个输入信号，输出一个信号。像电流流过导线，向前方输送
电子一样，感知机的信号也会形成流，向前方输送信息。但是，和实际的电
流不同的是，感知机的信号只有“流/不流”（1/0）两种取值。在本书中，0
对应“不传递信号”，1对应“传递信号”。

假设一个接收两个输入信号的感知机的例子。$x_1$、$x_2$是输入信号，
$y$ 是输出信号，$w_1$、$w_2$ 是权重（$w$ 是 weight 的首字母）。输入信号被送往神经元时，会被分别乘以固定的权重$(w_1x_1, w_2x_2)$，神经元会计算传送过来的信号的总和，只有当这个总和超过
了某个界限值时，才会输出1。这也称为“神经元被激活” 。这里将这个界
限值称为\textbf{阈值}，用符号$\theta$表示。

感知机的运行原理只有这些！把上述内容用数学式来表示：
\begin{equation}
    \label{eq2-1}
    y = \left \{
    \begin{array}{ll}
        0, & w_1x_1+w_2x_2  \leq \theta \\
        1, & w_1x_1+w_2x_2 > \theta     \\
    \end{array}
    \right.
\end{equation}

感知机的多个输入信号都有各自固有的权重，这些权重发挥着控制各个
信号的重要性的作用。也就是说，权重越大，对应该权重的信号的重要性就
越高。
\section{简单逻辑电路}
\subsection{与门}
与门（AND gate）是有两个输入和一个输出的门电路。与门仅在
两个输入均为1时输出1，其他时候则输出0。
\subsection{与非门和或门}
与非门（NAND gate）就是颠倒了与门的输出，仅当x1和x2同时为1时输出0，其他时候则输出1。

或门是“只要有一个输入信号是1，输出就为1”的逻辑电路。

\begin{tcolorbox}
    这里决定感知机参数的并不是计算机，而是我们人。我们看着真值
    表这种“训练数据”，人工考虑（想到）了参数的值。而机器学习的课
    题就是将这个决定参数值的工作交由计算机自动进行。学习是确定
    合适的参数的过程，而人要做的是思考感知机的构造（模型），并把
    训练数据交给计算机。
\end{tcolorbox}

与门、与非门、或门的感知机构造是一样的。
实际上，3个门电路只有参数的值（权重和阈值）不同。也就是说，相同构造
的感知机，只需通过适当地调整参数的值，就可以不断变换为与门、与非门、或门。

\section{感知机的实现}
\subsection{简单的实现}
\subsection{导入权重和偏置}
首先把 \autoref{eq2-1} 的$\theta$换成$-b$，就可以用 \autoref{eq2-2} 来表示感知机的行为。
\begin{equation}
    \label{eq2-2}
    y = \left \{
    \begin{array}{ll}
        0, & b+w_1x_1+w_2x_2  \leq 0 \\
        1, & b+w_1x_1+w_2x_2 > 0     \\
    \end{array}
    \right.
\end{equation}
这里，$b$称为偏置，$w_1$和$w_2$称为权重。感知机会计算输入
信号和权重的乘积，然后加上偏置，如果这个值大于0则输出1，否则输出0。请注意，偏置和权重$w_1$、$w_2$的作用是不
一样的。具体地说，$w_1$和$w_2$是控制输入信号的重要性的参数，而偏置是调
整神经元被激活的容易程度（输出信号为 1 的程度）的参数。

\section{感知机的局限性}
\subsection{异或门}
异或门也被称为逻辑异或电路。仅当$x_1$或$x_2$中的一方为
1时，才会输出1（“异或”是拒绝其他的意思）。实际上，用前面介绍的感知机是无法实现这个异或门的。

可以考虑在二维平面上添加一个直线，但是没有一个直线能够满足将$(0, 0), (0, 1), (1, 0), (1,1)$实现异或门的切分。

\subsection{线性和非线性}
显然，我们可以使用抛物线这种非线性的曲线来实现异或门，这就是用非线性的方式来实现的。\important{感知机的局限性就在于它只能表示由一条直线分割的空间}。由曲线分割而成的空间称为
非线性空间，由直线分割而成的空间称为线性空间。
\section{多层感知机}
感知机不能表示异或门让人深感遗憾，但也无需悲观。实际上，感知机
的绝妙之处在于它可以“叠加层”，这样可以实现异或门。
\subsection{已有门电路的组合}

\begin{tcolorbox}
    感知机的局限性，严格地讲，应该是“单层感知机无法
    表示异或门”或者“单层感知机无法分离非线性空间”。接下来，我
    们将看到通过组合感知机（叠加层）就可以实现异或门。
\end{tcolorbox}

异或门可以通过与门、与非门、或门组成的两层感知机来实现，首先是第一层：使用非门和与非门来作为输入，然后第二层使用非门和与非门的输出作为与门的输入，即可实现异或门。

\subsection{异或门的实现}
与门、或门是单层感知机，而异或门是2层感知机。叠加了多
层的感知机也称为多层感知机（multi-layered perceptron, MLP）。
\section{从与非门到计算机}
计算机是处理信息的机器。向计算机中输入一些信息后，它会按照某种
既定的方法进行处理，然后输出结果。所谓“按照某种既定的方法进行处理”
是指，计算机和感知机一样，也有输入和输出，会按照某个既定的规则进行
计算。